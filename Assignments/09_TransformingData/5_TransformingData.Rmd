# Transforming data

Sometimes long data needs to be wide, and sometimes wide data needs to be long. I'll explain.

You are soon going to discover that long before you can visualize data, you need to have it in a form that the visualization library can deal with. We started that with dates. One of the ways that isn't immediately obvious is how your data is cast. Most of the data you will encounter will be wide -- each row will represent a single entity with multiple measures for that entity. So think of states. Your dataset could have population, average life expectancy and other demographic data. 

But what if your visualization library needs one row for each measure? That's where recasting your data comes in. We can use a library called `tidyr` to `gather` or `spread` the data, depending on what we need.

We'll use our dataset of college basketball games. First we need some libraries. 

```{r}
library(dplyr)
library(tidyr)
library(readr)
```

Now we'll grab the data. 

```{r}
logs <- read_csv('~/Dropbox/SPMC350-Data-Literacy-and-Analytics-in-Sports/logs.csv')
```

```{r}
max <- logs %>% group_by(Team) %>% summarize(max_games = max(Game))
```

```{r}
logs <- logs %>% left_join(max)
```


```{r}
nebraska <- logs %>% filter(Team == "Nebraska Cornhuskers")
```

What we have here is long data. One row, one game. But what if we wanted to calculate the percent change in two variables? Say we wanted to see what the difference in shooting percentage has been between the first 10 games and the last five. Or the percent change in that? To get that, we'd need two fields next to each other so we could mutate our dataframe to calculate that, right? You'll see the problem we have right away. 

```{r}
nebraska %>% 
  mutate(grouping = case_when(
    Game <=10 ~ "First 10",
    Game >= (max_games - 5) ~ "Last 5")
    ) %>%
  group_by(Team, grouping) %>%
  summarize(
    shootingPCT = mean(TeamFGPCT)
  )
```
How do you write a mutate step to calulate the percent change when they're stacked on top of each other like that? Answer: You don't. You have to move the data around. 

To take long data and make it wide, we need to `spread` the data. That's the new verb. To spread the data, we tell spread what the new columns will be and what the data values that will go with them. Spread does the rest. 

So I'm going to take that same code and add spread to the bottom. I want the new columns to be my `grouping` and the data to be the `shootingPCT`.

```{r}
nebraska %>% 
  mutate(grouping = case_when(
    Game <=10 ~ "First 10",
    Game >= (max_games - 5) ~ "Last 5")
    ) %>%
  group_by(Team, grouping) %>%
  summarize(
    shootingPCT = mean(TeamFGPCT)
  ) %>% 
  spread(grouping, shootingPCT) 
```

And now, with it spread out, I can chain another mutate step onto it, adding my difference and my percent change. 

```{r}
nebraska %>% 
  mutate(grouping = case_when(
    Game <=10 ~ "First 10",
    Game >= (max_games - 5) ~ "Last 5")
    ) %>%
  group_by(Team, grouping) %>%
  summarize(
    shootingPCT = mean(TeamFGPCT)
  ) %>% 
  spread(grouping, shootingPCT) %>%
  mutate(
    change = ((`Last 5`-`First 10`)/`First 10`)*100,
    difference = (`First 10` - `Last 5`)*100
    )
```
So, over Nebraska's first 10 games, they shot almost 48 percent, where over the last five horrid games they're shooting 37 percent. That's an 11 percentage point different or a 24 percent drop from those first 10 games. 

We can't shoot the ball anymore.

How bad is that nationally? 

```{r}
logs %>% 
  mutate(grouping = case_when(
    Game <=10 ~ "First 10",
    Game >= (max_games - 5) ~ "Last 5")
    ) %>%
  group_by(Team, grouping) %>%
  summarize(
    shootingPCT = mean(TeamFGPCT)
  ) %>% 
  spread(grouping, shootingPCT) %>%
  mutate(
    change = ((`Last 5`-`First 10`)/`First 10`)*100,
    difference = (`First 10` - `Last 5`)*100
    ) %>% arrange(change)
```

Third. In all of college basketball. We've had the third biggest dropoff in all of college basketball from our first 10 games to our last five.

Thank God for Indiana.

### Making wide data long

We can reverse this process as well. If we get data that's wide and we want to make it long, we use `gather`. So first, since my data is already long, let me fake a wide dataset using what I just did. 

```{r}
gatherdata <- nebraska %>% 
  mutate(grouping = case_when(
    Game <=10 ~ "First 10",
    Game >= (max_games - 5) ~ "Last 5")
    ) %>%
  group_by(Team, grouping) %>%
  summarize(
    shootingPCT = mean(TeamFGPCT)
  ) %>% 
  spread(grouping, shootingPCT)
```

```{r}
head(gatherdata)
```

Oh drat, Sports Reference has given me wide data and for a visualization project, I need long data. Whatever will I do? This might seem silly, but two assignments from now, you're going to need long data from wide and wide data from long, so it's good to know. 

Gather, unfortunately, isn't as easy as spread. It can take some fiddling to get right. There's a ton of examples online if you Google for them, but here's what you do: You tell `gather` what the new column of data you are creating out of the field names first -- this is called the key -- and you then tell it what the value field is going to be called, which is usually a number. Have more than one thing to name your stuff with? After your key value pair, add it with a negative sign in front of it. 

```{r}
gatherdata %>% gather(grouping, shootingPCT, -Team)
```

And just like that, we're back where we started. 

### Why this matters

This matters because certain visualization types need wide or long data. A significant hurdle you will face for the rest of the semester is getting the data in the right format for what you want to do. 

So let me walk you through an example using this data. If I asked you to describe Nebraska's shooting performance over the season, we can do that by what we just did -- grouping them into the first 10 games when people actually talked about this team in the Sweet 16 and the last five when we aren't going to get an NIT bid. We can look at that shooting percentage, how it has changed, and that work makes for a perfect paragraph to write out. So to do that, you need wide data. 

But to visualize it, you need long. 

First, let's load our charting library, `ggplot2` which you're going to learn a lot more about soon.

```{r}
library(ggplot2)
```

Now I'm going to use that data and put the date of the game on the x axis, the shooting percentage on the y axis and then, for giggles, I'm going to add a best fit line that describes our season using a simple regression and the equation of a line. 

```{r}
ggplot(nebraska, aes(x=Date, y=TeamFGPCT)) + 
  geom_smooth(method='lm', se=FALSE, color="grey") + 
  geom_line() + 
  annotate("text", x=(as.Date("2018-12-08")), y=0.545, label="vs Creighton") + 
  annotate("text", x=(as.Date("2019-01-10")), y=0.502, label="vs Penn State") + 
  geom_point(aes(color = W_L)) + 
  scale_y_continuous(labels = scales::percent) + 
  labs(x="Date", y="FG percentage", title="Nebraska's season, visualized", subtitle="As the season goes by, the Huskers are getting worse at shooting the ball.", caption="Source: NCAA | By Matt Waite", color = "Outcome") +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 10),
    axis.title.y = element_blank(),
    axis.text = element_text(size = 7),
    axis.ticks = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    legend.position="bottom"
  ) + ggsave("nufg.png", width = 7, height = 5)
```

```{r}
fit <- lm(TeamFGPCT ~ Game, data=nebraska)
summary(fit)
confint(fit)
```

```{r}
(23 * -0.01094643) + 0.47117205
```

```{r}
(23 * -0.002939507) + 0.576334439
```




Oy. There it is. There's our season.

So I can tell you now, using wide data, that Nebraska's shooting performance over the last five games is down 24 percent from the first 10 games. And using long data, I can show you the story of the season, but without any specific stats to back it up. 

### Assignment

* Read [A Layered Grammar of Graphics](https://byrneslab.net/classes/biol607/readings/wickham_layered-grammar.pdf) by Hadley Wickham. 
* Watch Wickham, who created the libraries we are using, [work through a data project](https://www.youtube.com/watch?v=go5Au01Jrvs). 

